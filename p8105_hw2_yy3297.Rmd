---
title: "Homework 2 solutions"
author: "Yunxi Yang"
output: github_document
---

```{r setup}
library(tidyverse)
library(readxl)
```

### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations.

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

### Problem 2

```{r First read and clean the Mr. Trash Wheel collection data sheet}
mr_trash_wheel_df = 
  read_excel("Trash Wheel Collection Data.xlsx", range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(sports_balls = as.integer(sports_balls),
         year = as.integer(year)) 
mr_trash_wheel_df
```


```{r Then read and clean the Professor Trash Wheel collection data sheet}
prof_trash_wheel_df = 
  read_excel("Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = cell_cols("A:M")) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = as.integer(year)) 
prof_trash_wheel_df
```

```{r combine these two dataset}
combined_trash_df = bind_rows(mr_trash_wheel_df, prof_trash_wheel_df)
combined_trash_df
```

Descriptions about these data: 
1. The combined data set contains the variables of `r colnames(combined_trash_df)`.
2. There are totally `r nrow(combined_trash_df)` rows of observations, and `r ncol(combined_trash_df)` columns of observations.
3. The total weight of trash collected by Professor Trash Wheel is `r sum(prof_trash_wheel_df$weight_tons)` tons. 
4. The total number of sport balls collected by Mr. Trash Wheel in 2020 is `r sum(mr_trash_wheel_df$sports_balls, mr_trash_wheel_df$year == 2020)` balls. 


### Problem 3

```{r First, read and clean the data of pols_month}
pols_month_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(col = mon, into = c("year", "month", "day"), sep = '-', convert = TRUE) %>% 
  mutate(month = month.abb[month],
         president = ifelse(prez_gop == 1, "gop", "dem"),
         year = as.integer(year)) %>% 
  select(-prez_dem, -prez_gop, -day) %>% 
  arrange(year)
pols_month_df
```


```{r Second, read and clean the data of snp}
snp_df = 
  read_csv("fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(col = date, into = c("month", "day", "year"), sep = '/', convert = TRUE) %>% 
  arrange(year, month, day) %>%
  mutate(month = month.abb[month],
         year = ifelse(year > 15, year+1900, year+2000),
         year = as.integer(year)) %>%
  select(year, month, close) %>%
  arrange(year)
snp_df
```

```{r Third, read and clean the data of unemployment}
unemployment_df = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(Jan : Dec, names_to = "month", values_to = "unemployment_rate") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(year = as.integer(year)) %>%
  arrange(year)
unemployment_df
```

```{r Join the datasets by merging snp into pols_month, and merging unemployment into the result}
snp_into_pols_df = left_join(pols_month_df, snp_df, by = c('year', 'month'))
final_df = left_join(snp_into_pols_df, unemployment_df, by = c('year', 'month')) %>%
  arrange(year)
final_df
```

Descriptions about each data sets:
1. The pols_month data set contains the variables of `r colnames(pols_month_df)`, and there are `r nrow(pols_month_df)` rows and `r ncol(pols_month_df)` columns of observations. The range of years for this data set is `r range(pols_month_df$year)` years.
2. The snp data set contains the variables of `r colnames(snp_df)`, and there are `r nrow(snp_df)` rows and `r ncol(snp_df)` columns of observations. The range of years for this data set is `r range(snp_df$year)` years.
3. The unemployment data set contains the variables of `r colnames(unemployment_df)`, and there are `r nrow(unemployment_df)` rows and `r ncol(unemployment_df)` columns of observations. The range of years for this data set is `r range(unemployment_df$year)` years.
4. The final data set contains the variables of `r colnames(final_df)`, and it has `r nrow(final_df)` rows and `r ncol(final_df)` columns of observations. The range of years for this data set is `r range(final_df$year)` years.


